---
title: "R Notebook"
output: html_notebook
---

# =========================================================================
# Multi-Colinearity analysis
# Code by: Alos Diallo
# 2023,2024
# =========================================================================

Loading libraries:
```{r message=FALSE, warning=FALSE, include=FALSE}
library(minfi)
library(sesame)
library(pheatmap)
library(minfiData)
library(FlowSorted.Blood.EPIC)
library(HiTIMED)
library(ggplot2)
library(dplyr)
library(IlluminaHumanMethylationEPICanno.ilm10b4.hg19)
library(IlluminaHumanMethylationEPICv2manifest)
library(IlluminaHumanMethylationEPICv2anno.20a1.hg38)
library(IlluminaHumanMethylationEPICmanifest)
library(limma)
library(qvalue)
library(sva)
library(ENmix)
library(DataExplorer)
library(ggplot2)
library(ggrepel)
library(matrixStats)
library(EpiDISH)
library(tibble)
library(tidyr)
```



Loading the annotation file:
```{r}
data("IlluminaHumanMethylationEPICanno.ilm10b4.hg19")
anno <- getAnnotation(IlluminaHumanMethylationEPICanno.ilm10b4.hg19)

# Extract probes located on the Y chromosome
cpg_y_probes <- rownames(anno[anno$chr == "chrY", ])  # Filter probes on Y chromosome
```

Loading the data and metadata information
```{r}
targets <- read.csv("/Users/adiallo/Desktop/Thesis/Data_Documents/dm_57_samples.csv")
targets$patient <- paste(targets$Sentrix_ID,targets$Sentrix_Position,sep="_")
rownames(targets) <- targets$patient
targets$SampleID<- targets$patient

targets_expanded <- read.csv("/Users/adiallo/Desktop/Thesis/Data_Documents/data_all.csv")
targets_expanded$patient <- paste(targets$Sentrix_ID,targets$Sentrix_Position,sep="_")
rownames(targets_expanded) <- targets_expanded$patient
targets_expanded$SampleID<- targets_expanded$patient
```

```{r}
idat = "/Users/adiallo/Desktop/Thesis/Data_Documents/All_Data/DNA_Methylation/dm_data/no_match/"
RGset_32 = read.metharray.exp("/Users/adiallo/Desktop/Thesis/Data_Documents/All_Data/DNA_Methylation/dm_data/no_match/idats/",recursive = TRUE) 
#RGset_25 = openSesame(idat , func = getBetas) 
RGset_25 = read.metharray.exp("/Users/adiallo/Desktop/Thesis/Data_Documents/All_Data/DNA_Methylation/dm_data/no_match/25_samples/",recursive = TRUE) 
```

Looking for bad CpG's using QCinfo
```{r}
sva<-ctrlsva(RGset_32)
surrogateVariables <- sva
# Convert RGChannelSet to RGChannelSetExtended
RGset_32_extended <- read.metharray.exp("/Users/adiallo/Desktop/Thesis/Data_Documents/All_Data/DNA_Methylation/dm_data/no_match/idats/",recursive = TRUE,extended = TRUE)
RGset_25_extended <- read.metharray.exp("/Users/adiallo/Desktop/Thesis/Data_Documents/All_Data/DNA_Methylation/dm_data/no_match/25_samples/",recursive = TRUE,extended = TRUE) 

# Run QCinfo function
qc_info32 <- QCinfo(RGset_32_extended)
qc_info25 <- QCinfo(RGset_25_extended)

# Display QC information
#print(qc_info32)
#print(qc_info25)
badCpG = c(qc_info32$badCpG,qc_info25$badCpG)
# Remove any suffix after an underscore
cleaned_badCpG <- sub("_.*", "", badCpG)
```

Normalizing the data
```{r}
Noob_25_m = preprocessNoob(RGset_25)
Noob_32_m = preprocessNoob(RGset_32)
```

Extracting the beta values
```{r}
Betas_25<-getBeta(Noob_25_m)
Betas_32<-getBeta(Noob_32_m)
```

Colapsing the betas so that the data can be merged
```{r}
Betas_25<- sesame::betasCollapseToPfx(Betas_25)
#Betas_32<- sesame::betasCollapseToPfx(Betas_32)
colnames(Betas_25) = colnames(Noob_25_m)
```

Filter out sex linked probes
```{r}
# Filter Y chromosome probes from Betas_25
cpg_y_probes_in_betas_25 <- cpg_y_probes[cpg_y_probes %in% rownames(Betas_25)]
Betas_25_filtered <- Betas_25[!rownames(Betas_25) %in% cpg_y_probes_in_betas_25, ]

# Filter Y chromosome probes from Betas_32
cpg_y_probes_in_betas_32 <- cpg_y_probes[cpg_y_probes %in% rownames(Betas_32)]
Betas_32_filtered <- Betas_32[!rownames(Betas_32) %in% cpg_y_probes_in_betas_32, ]

# Extract probes located on the X chromosome
cpg_x_probes <- rownames(anno[anno$chr == "chrX", ])

# Filter X chromosome probes from Betas_25
cpg_x_probes_in_betas_25 <- cpg_x_probes[cpg_x_probes %in% rownames(Betas_25_filtered)]
Betas_25_filtered <- Betas_25_filtered[!rownames(Betas_25_filtered) %in% cpg_x_probes_in_betas_25, ]

# Filter X chromosome probes from Betas_32
cpg_x_probes_in_betas_32 <- cpg_x_probes[cpg_x_probes %in% rownames(Betas_32_filtered)]
Betas_32_filtered <- Betas_32_filtered[!rownames(Betas_32_filtered) %in% cpg_x_probes_in_betas_32, ]
```


Merging the samples 
```{r}
# Ensure the same probes exist in both datasets
common_probes <- intersect(rownames(Betas_25_filtered), rownames(Betas_32_filtered))

# Subset both datasets to include only common probes
Betas_25_filtered <- Betas_25_filtered[common_probes, ]
Betas_32_filtered <- Betas_32_filtered[common_probes, ]

# Combine the beta values from both datasets
DH_CRC_Betas <- cbind(Betas_25_filtered, Betas_32_filtered) 

```




Running HiTIMED to generate cell type proportions
```{r}
HiTIMED_result<-HiTIMED_deconvolution(DH_CRC_Betas,"COAD",6,"tumor")
```

Running EpiDISH to obtain fibroblast proportions
```{r}
# Define the beta matrix and reference matrix
beta_matrix <- DH_CRC_Betas  # Your dataset
ref_matrix <- centEpiFibIC.m  # Reference matrix for EpiDISH (e.g., centEpiFibIC.m)

# Run EpiDISH
epidish_results <- epidish(beta.m = beta_matrix, ref.m = ref_matrix, method = "RPC")

# Extract the estimated cell type proportions
cell_type_proportions <- epidish_results$estF

# Convert the matrix to a data frame and scale proportions to percentages
cell_type_proportions_df <- as.data.frame(cell_type_proportions) * 100

# Add SampleID as a column from the row names
cell_type_proportions_df$SampleID <- rownames(cell_type_proportions)

# Inspect the results
head(cell_type_proportions_df)
```

Examining Variance and limiting the dataset size
```{r}
# Assuming beta_matrix is a dataframe or matrix where rows are CpG sites and columns are samples

# Calculate variances for each CpG site
variances <- apply(DH_CRC_Betas, 1, var)

# Check summary statistics for variances
summary(variances)

# Create histogram of variances
hist(variances, breaks = 1000, main = "Variance Distribution of CpG Sites",
     xlab = "Variance", ylab = "Frequency", col = "skyblue")

# Add a vertical line for a tentative cutoff
abline(v = 0.005, col = "red", lwd = 2, lty = 2)

# Define the threshold for variance
threshold <- 0.01

# Count the number of CpG sites with variance greater than the threshold
num_above_threshold <- sum(variances > threshold)

# Print the result
cat("Number of CpG sites with variance > ", threshold, ": ", num_above_threshold, "\n")

# Proportion of CpGs retained
prop_retained <- num_above_threshold / length(variances)
cat("Proportion of CpG sites retained: ", round(prop_retained * 100, 2), "%\n")

# Count the number of CpG sites with variance <= threshold (to the left of the line)
num_below_threshold <- sum(variances <= threshold)

# Print the result
cat("Number of CpG sites with variance <= ", threshold, ": ", num_below_threshold, "\n")

temp = DH_CRC_Betas

# Recalculate logical indices
low_variance_indices <- variances <= threshold

DH_CRC_Betas <- DH_CRC_Betas[low_variance_indices, ]

```

Generate M values
```{r}
DH_CRC_M_value = BetaValueToMValue(DH_CRC_Betas)
```

Filter out bad CpG's
```{r}
# Identify good CpGs
all_cpgs <- rownames(DH_CRC_M_value)
good_cpgs <- setdiff(all_cpgs, cleaned_badCpG)
# Filter the M values to keep only good CpGs
filtered_DH_CRC_M_value <- DH_CRC_M_value[good_cpgs, ]
DH_CRC_M_value = filtered_DH_CRC_M_value
```


Setting up the model matrix
```{r}
# Step 1: Prepare Combined Data
HiTIMED_result$SampleID <- rownames(HiTIMED_result)

# Merge HiTIMED results, targets, and EpiDISH fibroblast data
combined_data <- HiTIMED_result %>%
  left_join(targets, by = "SampleID") %>%
  left_join(cell_type_proportions_df %>% select(SampleID, Fib), by = "SampleID")  # Add 'Fib' column

# Step 2: Filter out Rectal Samples
combined_data_filtered <- combined_data %>%
  filter(site != "rectum")

# Subset M-value matrix to exclude rectal samples
DH_CRC_M_value_filtered <- DH_CRC_M_value[, combined_data_filtered$SampleID]

# Step 3: Normalize Metadata Columns
combined_data_filtered <- combined_data_filtered %>%
  mutate(
    site = tolower(gsub(" ", "", site)),
    across(c("sex", "any_mets", "MLH1", "Distant_Mets", "ln_only", "node_stage"), as.factor),  # Convert to factors
    age = as.numeric(as.character(age))  # Ensure 'age' is numeric
  )

# Step 4: Define Relevant Columns for Analysis
relevant_columns <- c("SampleID", "MLH1", "Tumor", "Endothelial", "Epithelial", "Fib", 
                      "CD8mem", "Bmem", "DC", "Treg", "CD4mem", "age", "sex", 
                      "any_mets", "Distant_Mets", "ln_only","node_stage")

analysis_data <- combined_data_filtered %>%
  select(all_of(relevant_columns)) %>%
  column_to_rownames(var = "SampleID")  # Set row names for alignment with M-value matrix

# Check for NA values and ensure data consistency
if (sum(is.na(analysis_data)) > 0) {
  stop("NA values detected in analysis_data. Please investigate.")
}


# Step 5: Create Design Matrix
design <- model.matrix(
  ~ any_mets * MLH1 + age + sex + Tumor + Endothelial + Epithelial + Fib + Treg + CD4mem + CD8mem + Bmem + DC, 
  data = analysis_data
)

# Make column names unique for edge cases (e.g., interactions with similar terms)
colnames(design) <- make.names(colnames(design), unique = TRUE)

# Step 6: Verify Consistency Between Design Matrix and M-value Matrix
if (!all(rownames(design) == colnames(DH_CRC_M_value_filtered))) {
  stop("Sample IDs do not match between the design matrix and the beta values matrix.")
}

# Print Summary
print(dim(design))  # Size of the design matrix
print(colnames(design))  # Predictor names
```


Running the EWAS:
```{r}
# Step 1: Define the input data
M.val2 <- DH_CRC_M_value_filtered  # Ensure M-value matrix is filtered appropriately

# Step 2: Fit the linear model
# Create the linear model using lmFit and include correlation adjustment
lm_fit <- lmFit(M.val2, design)

# Step 3: Plot initial diagnostics
# Distribution of mean methylation levels
hist(lm_fit$Amean, main = "Distribution of Mean Methylation Levels", xlab = "Mean Methylation Level")

# Plot residual standard errors against average methylation levels
plotSA(lm_fit, main = "Residual Standard Errors vs. Average Methylation")

# Step 4: Filter probes based on expression cutoff
# Define a mean methylation cutoff to retain high-confidence probes
CutOff <- 2
keep <- lm_fit$Amean > CutOff
filtered_fit <- lm_fit[keep, ]

# Step 5: Refit the model with filtered probes and apply empirical Bayes moderation
fit2 <- eBayes(filtered_fit, trend = TRUE)

# Step 6: Plot post-filter diagnostics
plotSA(fit2, main = "Residual Standard Errors vs. Average Methylation (Filtered)")

# Step 7: Adjust p-values and calculate q-values
# Extract p-values for a specific coefficient of interest
# Extract log fold changes
p_values <- fit2$p.value[, 'any_metsTRUE.MLH11']
logFC <- fit2$coefficients[, 'any_metsTRUE.MLH11']

# Calculate q-values using the qvalue package
q_values <- qvalue(p_values)
summary(q_values)

# Step 8: Generate a results table
# Extract top results with BH adjustment
results_table <- topTable(fit2, coef = 'any_metsTRUE.MLH11', adjust = "BH", n = Inf)

# Step 9: Plot the distribution of average methylation levels (optional visualization)
hist(rowMeans(M.val2), main = "Distribution of Mean Methylation Levels", xlab = "Mean Methylation Level")

# Output: Summary of results
print(head(results_table))  # View top results
print(summary(q_values))    # View summary of q-values
```

```{r}
# Calculate correlation matrix for the design matrix
cor_matrix <- cor(design[, -which(colnames(design) == "X.Intercept.")])

# Visualize correlation matrix as a heatmap
library(ggcorrplot)
ggcorrplot(cor_matrix, hc.order = TRUE, type = "lower", lab = TRUE)
```
```{r}
# Convert design matrix to data frame
design_df <- as.data.frame(design[, -which(colnames(design) == "X.Intercept.")])

# Fit the model using lm()
lm_model <- lm(M.val2[1, ] ~ ., data = design_df)

# Run VIF analysis
library(car)
vif_result <- vif(lm_model)
print(vif_result)
```
Trying to address multicolinearity 
```{r}
design_df$Endothelial <- scale(design_df$Endothelial, center = TRUE, scale = FALSE)
design_df$Fib <- scale(design_df$Fib, center = TRUE, scale = FALSE)
design_df$Tumor <- scale(design_df$Tumor, center = TRUE, scale = FALSE)

# Fit the model using lm()
lm_model <- lm(M.val2[1, ] ~ ., data = design_df)

# Run VIF analysis
library(car)
vif_result <- vif(lm_model)
print(vif_result)
```
SVA analysis
```{r}
# Full model
mod <- model.matrix(~ any_metsTRUE + MLH11 + age + sexM + Tumor + Endothelial + Fib + CD8mem + DC, data = design_df)

# Null model
mod0 <- model.matrix(~ age + sexM, data = design_df)

library(sva)
sva_results = sva(dat = M.val2, mod = mod, mod0 = mod0)

surrogate_vars <- sva_results$sv

# Transpose M.val2 to align dimensions with surrogate_vars
M.val2_t <- t(M.val2)  # Now samples are rows, and probes are columns

# Perform matrix multiplication
fitted_values <- surrogate_vars %*% solve(t(surrogate_vars) %*% surrogate_vars) %*% t(surrogate_vars) %*% M.val2_t
# Fit a linear model for each probe using the surrogate variables

# Transpose fitted_values back to match the original M.val2 dimensions
fitted_values <- t(fitted_values)  # Dimensions are now 412622 Ã— 57

# Residuals
residuals <- M.val2 - fitted_values

# Total variance in the data
total_variance <- sum(apply(M.val2, 1, var))

# Variance explained by surrogate variables
explained_variance <- sum(apply(fitted_values, 1, var))

# Percentage of variance explained
percentage_variance_explained <- (explained_variance / total_variance) * 100

print(paste("Percentage of variance explained by surrogate variables:", percentage_variance_explained, "%"))
```

Looking at the model with the surrogates attached
```{r}
# Add surrogate variables to the design matrix
design_with_sv <- cbind(design_df, surrogate_vars)


colnames(design_with_sv)[(ncol(design_df) + 1):ncol(design_with_sv)] <- paste0("SV", 1:ncol(surrogate_vars))

mod_with_sv <- model.matrix(~ any_metsTRUE + MLH11 + age + sexM + Tumor + Endothelial + Fib + CD8mem + DC + SV1 + SV2 + SV3 + SV4 + SV5 + SV6 + SV7 + SV8, data = design_with_sv)
```

```{r}
# Fit the model using limma
library(limma)
fit <- lmFit(M.val2, mod_with_sv)
fit <- eBayes(fit)

# Extract results for your primary variable of interest (e.g., any_metsTRUE)
results <- topTable(fit, coef = "any_metsTRUE", adjust = "fdr")
```


```{r}
fitted_values <- fitted(fit)
residuals <- M.val2 - fitted_values
residual_variance <- sum(apply(residuals, 1, var))
print(paste("Residual variance after including SVs:", residual_variance))
```

```{r}
total_variance <- sum(apply(M.val2, 1, var))
proportion_explained <- 1 - (residual_variance / total_variance)
print(paste("Proportion of variance explained by the model:", proportion_explained * 100, "%"))
```

Now lets look at the amount of variance when we don't include SV's
```{r}
# Step 1: Fit a model without SVs
mod_without_sv <- model.matrix(~ any_metsTRUE + MLH11 + age + sexM + Tumor + Endothelial + Fib + CD8mem + DC, data = design_df)

# Step 2: Fit the model using limma
library(limma)
fit_without_sv <- lmFit(M.val2, mod_without_sv)

# Step 3: Extract fitted values from the model
fitted_values_without_sv <- fitted(fit_without_sv)

# Step 4: Calculate residuals and residual variance without SVs
residuals_without_sv <- M.val2 - fitted_values_without_sv
residual_variance_without_sv <- sum(apply(residuals_without_sv, 1, var))

# Step 5: Calculate total variance in the dataset
total_variance <- sum(apply(M.val2, 1, var))

# Step 6: Calculate the proportion of variance explained without SVs
proportion_explained_without_sv <- 1 - (residual_variance_without_sv / total_variance)
print(paste("Proportion of variance explained without SVs:", proportion_explained_without_sv * 100, "%"))

# Step 7: Compare with the proportion of variance explained with SVs
# Assuming you already have residual_variance_with_sv from the earlier analysis:
proportion_explained_with_sv <- 1 - (residual_variance / total_variance)
print(paste("Proportion of variance explained with SVs:", proportion_explained_with_sv * 100, "%"))

# Optional: Difference in variance explained
difference <- proportion_explained_with_sv - proportion_explained_without_sv
print(paste("Difference in variance explained (impact of SVs):", difference * 100, "%"))
```




























